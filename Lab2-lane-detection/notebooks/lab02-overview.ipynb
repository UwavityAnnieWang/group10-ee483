{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# <p style=\"text-align: center;\"> <span style=\"color:yellowgreen\"> Lab 2 - Lane detector </span></p>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In Lab 1, we used open-loop control to drive the MM around the block.   \n",
                "After a lot of tuning, you can use open-loop control to complete the goal.  \n",
                "However, there should be a better way.  \n",
                "Our first step is to sense the world around the MM: use the camera!!!  \n",
                "This is our first step towards autonomy.  \n",
                "\n",
                "In Lab 2, we will use the camera to detect the lanes in Duckietown.  \n",
                "You will create your own lane detector for the MMs.   \n",
                "Moreover, you will compare your lane detector against a competitor the `Duckiebots`.  \n",
                "This comparison will be qualitative but you should be able to get a sense of how well you did.   \n",
                "\n",
                "The *goal* of this lab is to create a package that makes the MM (robot) detect lanes in Duckietown  \n",
                "You will create and test your package directly in **the physical MM (robot).** ðŸ¦† (no simulation)  \n",
                "Later on, we will use your node to compute the position of the MM in the lane. \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <p style=\"text-align: center;\"> <span style=\"color:coral\"> Objectives </span></p>\n",
                "1. Create a package. The name of the package must be **lab2**.\n",
                "\n",
                "2. Create one node (one python script):\n",
                "\n",
                "\ta. The name of the node must be **lanedetector.py**  \n",
                "\tb. You MUST publish an image with the line segments drawn on, similar to the Duckietown debug image.\n",
                "\t\n",
                "\n",
                "3. A launch file to start your node. The name of the launch file must be **lab2.launch**.\n",
                "\n",
                "### ROS Package\n",
                "Your package will depend on rospy, roscpp, std_msgs, geometry_msgs, duckietown_msgs, cv_bridge. \n",
                "\n",
                "Name of the package is **lab2**\n",
                "\n",
                "### ROS Nodes\n",
                "You already have most of the code needed to complete this assignment from Exs 4 and 5.   \n",
                "It is recommended to combine these nodes into one node with only one callback.   \n",
                "Usually, we prefer multiple smaller nodes for modularity purposes.  \n",
                "However, this comes with the cost of sending and receiving several images which can produce lagging in embedded systems such as the Jetson Nano.   \n",
                "Therefore, we recommend to combine your nodes from Exs 4 and 5 into one node that subscribes to the image from the MM camera and outputs the resulting line segments post-line detection.   \n",
                "The MM publishes the camera image in the topic `/ee483mm<number>/camera_node/image/compressed`.\n",
                "\n",
                "\n",
                "For debugging purposes, you may wish to publish the output of each step, e.g., cropped image, mask, edge detection, etc.   \n",
                "You MUST publish an image with the line segments drawn on, similar to the Duckietown debug image.   \n",
                "\n",
                "**Lane Detector Node**: \n",
                "This node will be a combination of your nodes in Exs 4 and 5.  \n",
                "The node should perform the following:\n",
                "- (a) Subscribe to the image topic: `/ee483mm<number>/camera_node/image/compressed`\n",
                "- (b) Crop the image in at least half (to observe only the lane in front of the MM)  \n",
                "- (c) Filter for white pixels such that you can clearly see at least the lane marker on the right of the MM.\n",
                "- (d) Perform Canny edge detection on the cropped image.\n",
                "- (e) Combine the result of edge detection with the white filtered image using the OpenCV bitwise_and operator.  \n",
                "This should produce an image composed of just the boundaries of the white lanes. If not, refine your filter and/or edge detector.  \n",
                "You may need to tune your erode/dilate steps from Ex 4 to do this. \n",
                "- (f) Perform a Hough transform on the image resulting from the step (e).\n",
                "- (g) Draw lines found in the Hough transform on the cropped image from step (b).  \n",
                "Your code should produce one color image with lines on it for the white lane markers\n",
                "\n",
                "Although only the image from step (g) MUST be published, you might find helpful to publish the image from each step for debugging.\n",
                "\n",
                "\n",
                "\n",
                "- **Note**- ROS nodes will start at different times, so consider adding a slight delay before publishing commands.\n",
                "Add a delay of at least 2-3 seconds in the beginning of your node python script.  \n",
                "\n",
                "### ROS Launch file\n",
                "The name of the launch file must be **lab2.launch**   \n",
                "Your launch file must start:\n",
                "1. Your lane detector node\n",
                "\n",
                "## Notebooks information \n",
                "\n",
                "There are 4 notebooks covering:\n",
                "- MM camera calibration (lab02a)\n",
                "- Observing the MM's camera (lab02b) \n",
                "- Running the competitors code (lab2c) \n",
                "- Creating your own lane detector (lab2d)\n",
                "\n",
                "You can use these detailed instructions to complete this assignment.   \n",
                "However, many different solutions are possible.   \n",
                "Creativity is encouraged!\n",
                "\t"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## <p style=\"text-align: center;\"> <span style=\"color:coral;\">Submission </span></p>\n",
                "**Only one of the group member will create the tag**\n",
                "\n",
                "1. Check which files changed\n",
                "```bash\n",
                "git status\n",
                "```  \n",
                "2. Add them to this staged commit\n",
                "```bash\n",
                "git add -A\n",
                "```\n",
                "3. Make the commit\n",
                "```bash\n",
                "git commit -m 'your message for the commit'\n",
                "```\n",
                "4. Push it to your repo on GitHub\n",
                "```bash\n",
                "git push\n",
                "```\n",
                "Up to this point, your git should be updated. The next commands are for the final exercise or lab submission\n",
                "\n",
                "5. Tag based lab1.\n",
                "```bash\n",
                "git tag lab2\n",
                "```\n",
                "6. Push the tag to Github\n",
                "```bash\n",
                "git push origin lab2\n",
                "```\n",
                "7. Verify on Github.com that your submission is there, in the correct tag\n",
                "\n",
                "### Rubric\n",
                "\n",
                "- Package creation 5%\n",
                "- Launch file 5%\n",
                "- Git tag 5%\n",
                "- Lane detector node 70% (**DEMONSTRATE IN THE LAB**) You will drive it manually in the track and showing your lane detection image output. \n",
                "\t- Algorithm 40 %\n",
                "\t\t- Color filtering 10 %\n",
                "\t\t- Edge detection 10 %\n",
                "\t\t- Hough transformation 20%\n",
                "\t- Implementation 10 %\n",
                "\t\t- Node implementation 5 %\n",
                "\t\t- Speed considerations (described in notebook 02d) 5 %\n",
                "\t- Quality of the detector 20 %\n",
                "\n",
                "- Lab report 15% (only one member submits on Canvas)\n",
                "\t1. Provide name of group members and a link to your lab repo\n",
                "\t2. A description of each group member role in completing the assignment\n",
                "\t3. A paragraph explaining how you think your lane detector compares with the Duckietown lane detector. When does it do better/worse? Why might that be? E.g., light conditions, corners, etc. \n",
                "\t4. Screenshots of your filter versus the Duckiebot filter.  \n",
                "\t5. A description of any issues you had with this assignment.\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8.10 64-bit",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        },
        "vscode": {
            "interpreter": {
                "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
